You are given a dataset of instructions, two model outputs (output_a and output_b), and a preference label.

Your task is to **decompose both outputs** into their cognitive structure by identifying:
1. **Meta-Cognitive Plan (M)** — the part of the response that reflects the model’s self-guided approach, such as trying to clarify the question, reflect on ethical implications, or selecting a tone or style.
2. **Tactical Execution Plan (T)** — the part that reflects how the model executes the plan, e.g., outlining steps, giving examples, choosing an argumentative structure.
3. **Answer (A)** — the part where the model gives a direct response to the query.

For each of these components in `output_a` and `output_b`, you must:
- Extract the **text span indices** from the original output: [start_token_index, end_token_index]
- Provide a **brief explanation** of what that component represents in that span
- Include an optional short **strategy label** summarizing the style used

Return the output in the following format:
{
  "query": <original query>,
  "M_a_text": <meta-plan for output_a>,
  "M_a_span": [M_start, M_end],
  "T_a_text": <tactical plan for output_a>,
  "T_a_span": [M_end, T_end],
  "A_a_text":  <original output_a>,
  "A_a_span": [T_end, A_end],
  "S_a": <strategy name for output_a>,
  "M_b_text": <meta-plan for output_b>,
  "M_b_span": [M_start, M_end],
  "T_b_text": <tactical plan for output_b>,
  "T_b_span": [M_end, T_end],
  "A_b_text":  <original output_b>,
  "A_b_span": [T_end, A_end],
  "S_b": <strategy name for output_b>,
  "label": <original label>
}

### Rules:
- The `*_span` indices are **token-level** (space-separated word count).
  - Count words from 0 onward, based on tokenization with spaces.
- `*_text` fields should briefly explain *why* that part is M, T, or A — not just repeat the output.
- The `*_span` must correspond to **actual words in the output**, not invented summaries.
- If M or T is not clearly present, mark the span as an empty list: `[]` and text as `"Not explicitly present"`
- Strategy labels (S_a, S_b) should be short, clear titles (e.g. "Clarify Then Answer", "List & Justify")

### Example Tokenization (for indexing):

Input:
{
  "query": "Is it okay to lie sometimes?",
  "output_a": "No, lying is unethical in most circumstances...",
  "output_b": "It depends on the context. Sometimes lying can prevent harm...",
  "label": 1
}

For output_a: `"No, lying is unethical in most circumstances...."`

Tokens would be:
[0] "No,"
[1] "lying"
[2] "is"
[3] "unethical"
[4] "in"
[5] "most"
[6] "circumstances."
...

So the span [0, 6] includes the full answer.

{
  "query": "Is it okay to lie sometimes?",
  "M_a_text": "Respond with a firm ethical stance to establish clarity.",
  "M_a_span": [15, 23],
  "T_a_text": "State the moral rule, then explain its implications.",
  "T_a_span": [7, 14],
  "A_a_text": "No, lying is unethical in most circumstances.",
  "A_a_span": [0, 6],
  "S_a": "Ethics-First Reasoning",

  "M_b_text": "Acknowledge the complexity and provide a context-aware analysis.",
  "M_b_span": [0, 4],
  "T_b_text": "Start with a conditional view, then justify with examples.",
  "T_b_span": [5, 12],
  "A_b_text": "It depends on the context. Sometimes lying can prevent harm...",
  "A_b_span": [13, 26],
  "S_b": "Contextual Moral Analysis",

  "label": 1
}
---

Process each query and its outputs into this structure. Output only the JSON-formatted object. Do not add any commentary or explanation.
